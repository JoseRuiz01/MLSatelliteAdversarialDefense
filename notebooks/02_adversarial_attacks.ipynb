{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ef115af",
   "metadata": {},
   "source": [
    "# PGD attacks\n",
    "\n",
    "This notebook tests **EuroSAT ResNet18 model** on images modified with **PGD attacks**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "859d9f70",
   "metadata": {},
   "source": [
    "### 1. Setup environment and imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d449ca6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import sys, os\n",
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import models\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import glob\n",
    "import numpy as np\n",
    "\n",
    "from src.training.simple_cnn import SimpleCNN\n",
    "from src.data.dataloader import get_dataloaders, compute_mean_std\n",
    "from src.attacks.pgd import evaluate_pgd\n",
    "from src.attacks.evaluate import evaluate_adv, plot_confusion_matrix\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "model_name = \"simplecnn\" # or resnet18\n",
    "data_dir = '../data/raw'\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e182d54",
   "metadata": {},
   "source": [
    "- Get path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b4903627",
   "metadata": {},
   "outputs": [],
   "source": [
    "if model_name == \"simplecnn\":\n",
    "        checkpoint_path = \"../experiments/checkpoints/simplecnn_best.pth\"\n",
    "elif model_name == \"resnet18\":\n",
    "    checkpoint_path = \"../experiments/checkpoints/resnet18_best.pth\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "528f49e1",
   "metadata": {},
   "source": [
    "### 2. Load data and model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "946b611e",
   "metadata": {},
   "source": [
    "- Load dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0d388079",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 10 classes: ['AnnualCrop', 'Forest', 'HerbaceousVegetation', 'Highway', 'Industrial', 'Pasture', 'PermanentCrop', 'Residential', 'River', 'SeaLake']\n"
     ]
    }
   ],
   "source": [
    "train_loader, val_loader, test_loader, classes = get_dataloaders(data_dir=data_dir, batch_size=batch_size)\n",
    "print(f'Loaded {len(classes)} classes: {classes}')\n",
    "\n",
    "num_classes = len(classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ac97b7d",
   "metadata": {},
   "source": [
    "- Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8b269473",
   "metadata": {},
   "outputs": [],
   "source": [
    "if model_name.lower() == \"resnet18\":\n",
    "    model = models.resnet18(weights=models.ResNet18_Weights.DEFAULT)\n",
    "    model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "elif model_name.lower() == \"simplecnn\":\n",
    "    model = SimpleCNN(num_classes=num_classes)\n",
    "else:\n",
    "    raise ValueError(f\"Unsupported model_name: {model_name}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a616a35",
   "metadata": {},
   "source": [
    "### 3. Run PGD attacks and save adversarial images "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d71445b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m out_dir = \u001b[33m'\u001b[39m\u001b[33m../data/adversarial/pgd\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m      2\u001b[39m eps=\u001b[32m1e-09\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m res = \u001b[43mevaluate_pgd\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdataloader\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m    \u001b[49m\u001b[43meps\u001b[49m\u001b[43m=\u001b[49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m    \u001b[49m\u001b[43mout_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mout_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m    \u001b[49m\u001b[43msave_every\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_save\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m200\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtargeted\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     13\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtarget_class\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\n\u001b[32m     14\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     15\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m'\u001b[39m\u001b[33mPGD run result:\u001b[39m\u001b[33m'\u001b[39m, res)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Code/Python/ml-satellite-adv/src/attacks/pgd.py:110\u001b[39m, in \u001b[36mevaluate_pgd\u001b[39m\u001b[34m(model, dataloader, device, eps, alpha, iters, out_dir, save_every, max_save, targeted, target_class)\u001b[39m\n\u001b[32m    107\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    108\u001b[39m         target_labels = torch.full_like(labels, fill_value=\u001b[38;5;28mint\u001b[39m(target_class), device=device)\n\u001b[32m--> \u001b[39m\u001b[32m110\u001b[39m adv_images = \u001b[43mpgd_attack_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meps\u001b[49m\u001b[43m=\u001b[49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malpha\u001b[49m\u001b[43m=\u001b[49m\u001b[43malpha\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miters\u001b[49m\u001b[43m=\u001b[49m\u001b[43miters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    111\u001b[39m \u001b[43m                              \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargeted\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtargeted\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_labels\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtarget_labels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    113\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m    114\u001b[39m     out_adv = model(adv_images)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Code/Python/ml-satellite-adv/src/attacks/pgd.py:55\u001b[39m, in \u001b[36mpgd_attack_batch\u001b[39m\u001b[34m(model, images, labels, eps, alpha, iters, device, targeted, target_labels)\u001b[39m\n\u001b[32m     53\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     54\u001b[39m     loss = nn.CrossEntropyLoss()(outputs, labels)\n\u001b[32m---> \u001b[39m\u001b[32m55\u001b[39m     grad_sign = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mautograd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgrad\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madv_images\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m[\u001b[32m0\u001b[39m].sign()\n\u001b[32m     56\u001b[39m     adv_images = adv_images + alpha * grad_sign\n\u001b[32m     58\u001b[39m delta = torch.clamp(adv_images - ori_images, \u001b[38;5;28mmin\u001b[39m=-eps, \u001b[38;5;28mmax\u001b[39m=eps)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Code/Python/ml-satellite-adv/.venv/lib/python3.13/site-packages/torch/autograd/__init__.py:503\u001b[39m, in \u001b[36mgrad\u001b[39m\u001b[34m(outputs, inputs, grad_outputs, retain_graph, create_graph, only_inputs, allow_unused, is_grads_batched, materialize_grads)\u001b[39m\n\u001b[32m    499\u001b[39m     result = _vmap_internals._vmap(vjp, \u001b[32m0\u001b[39m, \u001b[32m0\u001b[39m, allow_none_pass_through=\u001b[38;5;28;01mTrue\u001b[39;00m)(\n\u001b[32m    500\u001b[39m         grad_outputs_\n\u001b[32m    501\u001b[39m     )\n\u001b[32m    502\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m503\u001b[39m     result = \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    504\u001b[39m \u001b[43m        \u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    505\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgrad_outputs_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    506\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    507\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    508\u001b[39m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    509\u001b[39m \u001b[43m        \u001b[49m\u001b[43mallow_unused\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    510\u001b[39m \u001b[43m        \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    511\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    512\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m materialize_grads:\n\u001b[32m    513\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(\n\u001b[32m    514\u001b[39m         result[i] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_tensor_like(inputs[i])\n\u001b[32m    515\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(inputs))\n\u001b[32m    516\u001b[39m     ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Code/Python/ml-satellite-adv/.venv/lib/python3.13/site-packages/torch/autograd/graph.py:841\u001b[39m, in \u001b[36m_engine_run_backward\u001b[39m\u001b[34m(t_outputs, *args, **kwargs)\u001b[39m\n\u001b[32m    839\u001b[39m     unregister_hooks = _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[32m    840\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m841\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_execution_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[32m    842\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    843\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[32m    844\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    845\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "out_dir = '../data/adversarial/pgd'\n",
    "eps=1e-09\n",
    "\n",
    "res = evaluate_pgd(\n",
    "    model=model,\n",
    "    dataloader=test_loader,\n",
    "    device=device,\n",
    "    eps=eps,\n",
    "    out_dir=out_dir,\n",
    "    save_every=20, \n",
    "    max_save=64,\n",
    "    targeted=False, \n",
    "    target_class=None\n",
    ")\n",
    "print('PGD run result:', res)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c941db19",
   "metadata": {},
   "source": [
    "### 4. Evaluate saved adversarial images for each epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "006de99a",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = f'../data/adversarial/pgd'\n",
    "\n",
    "if not os.path.isdir(folder):\n",
    "    print(f\"No folder found for eps={eps}: {folder}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fc6ad9f",
   "metadata": {},
   "source": [
    "- Evaluation of metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d59f2d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\n=== Evaluation on adversarial folder eps={eps} ===\")\n",
    "metrics_adv = evaluate_adv(\n",
    "    adv_folder=folder,\n",
    "    model_path=checkpoint_path,\n",
    "    data_dir=data_dir,          \n",
    "    batch_size=batch_size,\n",
    "    model_name=model_name,\n",
    "    device=device,\n",
    "    mean_std_sample_size=2000\n",
    ")\n",
    "\n",
    "print(f\"Num images: {metrics_adv['num_images']}\")\n",
    "\n",
    "print(f\"Accuracy: {metrics_adv['accuracy']*100:.2f}%\")\n",
    "print(f\"Loss: {metrics_adv['loss']:.4f}\")\n",
    "print(f\"Precision: {metrics_adv['precision']:.4f}\")\n",
    "print(f\"Recall: {metrics_adv['recall']:.4f}\")\n",
    "print(f\"F1-score: {metrics_adv['f1']:.4f}\")\n",
    "\n",
    "print(\"\\nClassification metrics per category:\\n\\n\", metrics_adv[\"classification_report\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aa240e1",
   "metadata": {},
   "source": [
    "- Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01c2d153",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(metrics_adv['confusion_matrix'], metrics_adv['class_names'], normalize=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f77f19d1",
   "metadata": {},
   "source": [
    "- Show a small sample of images "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea1cca79",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_paths = sorted(glob.glob(os.path.join(folder, '*.png')))[:10]\n",
    "if len(sample_paths) == 0:\n",
    "    print(\"No images to display.\")\n",
    "    \n",
    "else:\n",
    "    cols = 5\n",
    "    rows = (len(sample_paths) + cols - 1) // cols\n",
    "    plt.figure(figsize=(cols*2, rows*2))\n",
    "    for i, p in enumerate(sample_paths):\n",
    "        img = Image.open(p).convert(\"RGB\")\n",
    "        ax = plt.subplot(rows, cols, i+1)\n",
    "        ax.axis('off')\n",
    "        plt.imshow(img)\n",
    "    plt.suptitle(f'Adversarial examples (eps={eps})')\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
