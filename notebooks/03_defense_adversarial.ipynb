{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b230e62d",
   "metadata": {},
   "source": [
    "# Adversarial Training Defense for EuroSAT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63c6a840",
   "metadata": {},
   "source": [
    "### 1. Setup environment and imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30976eaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import sys, os, torch, torch.nn as nn, torch.optim as optim\n",
    "from torchvision import models\n",
    "from tqdm import tqdm\n",
    "from typing import Optional, Tuple\n",
    "from dataclasses import dataclass\n",
    "\n",
    "\n",
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "from src.data.dataloader import get_dataloaders\n",
    "from src.attacks.utils import extract_mean_std\n",
    "from src.training.evaluate import evaluate_model\n",
    "from src.attacks.pgd import pgd_attack_batch\n",
    "from src.attacks.metrics_eval import evaluate_adv, plot_confusion_matrix  \n",
    "\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class PGDConfig:\n",
    "    eps: float = 0.005\n",
    "    alpha: Optional[float] = None   \n",
    "    iters: int = 50\n",
    "    small_step_fraction: float = 0.2\n",
    "    grad_mask_fraction: float = 0.25\n",
    "    grad_blur_sigma: float = 1.0\n",
    "    smooth_perturb_sigma: float = 1.0\n",
    "    random_dither: bool = True\n",
    "    dither_scale: float = 0.5\n",
    "    device: Optional[torch.device] = None\n",
    "\n",
    "\n",
    "\n",
    "# Device setup\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"üöÄ Using device: {device}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c77d994",
   "metadata": {},
   "source": [
    "### 2. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b28f1fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model_name = \"resnet50\"\n",
    "data_dir = \"../data/raw\"\n",
    "checkpoint_dir = \"../experiments/checkpoints\"\n",
    "checkpoint_path = os.path.join(checkpoint_dir, f\"{model_name}_e2.pth\")\n",
    "adv_checkpoint_path = os.path.join(checkpoint_dir, f\"{model_name}_adv_trained.pth\")\n",
    "\n",
    "epochs = 20\n",
    "batch_size = 32\n",
    "lr = 5e-5\n",
    "epsilon = 0.005 \n",
    "alpha = epsilon / 10\n",
    "pgd_steps = 10\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f763f6cf",
   "metadata": {},
   "source": [
    "\n",
    "### 3. Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "929af6df",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_loader, val_loader, test_loader, classes = get_dataloaders(\n",
    "    data_dir=data_dir, batch_size=batch_size\n",
    ")\n",
    "num_classes = len(classes)\n",
    "print(f\"‚úÖ Loaded {num_classes} classes.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16e33280",
   "metadata": {},
   "source": [
    "### 4. Load pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e5e8363",
   "metadata": {},
   "outputs": [],
   "source": [
    "if model_name.lower() == \"resnet50\":\n",
    "    model = models.resnet50(weights=models.ResNet50_Weights.DEFAULT)\n",
    "    model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "elif model_name.lower() == \"resnet18\":\n",
    "    model = models.resnet18(weights=models.ResNet18_Weights.DEFAULT)\n",
    "    model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "else:\n",
    "    raise ValueError(f\"Unsupported model_name: {model_name}\")\n",
    "\n",
    "model.load_state_dict(torch.load(checkpoint_path, map_location=device))\n",
    "model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "print(f\"üì¶ Loaded pretrained weights from {checkpoint_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97df68d2",
   "metadata": {},
   "source": [
    "### 5. Adversarial Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a6a6d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_adversarial(\n",
    "    model,\n",
    "    train_loader,\n",
    "    criterion,\n",
    "    optimizer,\n",
    "    device,\n",
    "    eps=0.005,\n",
    "    alpha=None,\n",
    "    steps=10,\n",
    "    epochs=20,\n",
    "    grad_mask_fraction=0.25,\n",
    "    smooth_sigma=1.0,\n",
    "    dither_scale=0.3\n",
    "):\n",
    "    \"\"\"\n",
    "    Adversarial training loop using the SAME PGD implementation\n",
    "    used in evaluate_pgd(), ensuring consistency between training and testing.\n",
    "    \"\"\"\n",
    "\n",
    "    # --------------------------------------------------\n",
    "    # Use same normalization parameters as in evaluation\n",
    "    # --------------------------------------------------\n",
    "    mean_t, std_t = extract_mean_std(train_loader)\n",
    "    if alpha is None:\n",
    "        alpha = eps * 0.2  \n",
    "\n",
    "    # --------------------------------------------------\n",
    "    # Build PGD configuration (same as evaluate_pgd)\n",
    "    # --------------------------------------------------\n",
    "    pgd_conf = PGDConfig(\n",
    "        eps=eps,\n",
    "        alpha=alpha,\n",
    "        iters=steps,\n",
    "        small_step_fraction=0.2,\n",
    "        grad_mask_fraction=grad_mask_fraction,\n",
    "        grad_blur_sigma=1.0,\n",
    "        smooth_perturb_sigma=smooth_sigma,\n",
    "        random_dither=True,\n",
    "        dither_scale=dither_scale,\n",
    "        device=device,\n",
    "    )\n",
    "\n",
    "    # --------------------------------------------------\n",
    "    # Training Loop\n",
    "    # --------------------------------------------------\n",
    "    model.to(device)\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        total, correct = 0, 0\n",
    "\n",
    "        loop = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs}\", leave=False)\n",
    "\n",
    "        for images, labels in loop:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            # -----------------------------------------\n",
    "            # Generate PGD adversarial samples (batch)\n",
    "            # -----------------------------------------\n",
    "            adv_images = pgd_attack_batch(\n",
    "                model=model,\n",
    "                images=images,\n",
    "                labels=labels,\n",
    "                config=pgd_conf,\n",
    "                targeted=False,\n",
    "                target_labels=None,\n",
    "            )\n",
    "\n",
    "            # -----------------------------------------\n",
    "            # Combine clean + adversarial samples\n",
    "            # -----------------------------------------\n",
    "            combined_images = torch.cat([images, adv_images], dim=0)\n",
    "            combined_labels = torch.cat([labels, labels], dim=0)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(combined_images)\n",
    "            loss = criterion(outputs, combined_labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # -----------------------------------------\n",
    "            # Metrics\n",
    "            # -----------------------------------------\n",
    "            running_loss += loss.item()\n",
    "            _, preds = outputs.max(1)\n",
    "            correct += (preds == combined_labels).sum().item()\n",
    "            total += combined_labels.size(0)\n",
    "\n",
    "        print(\n",
    "            f\"Epoch [{epoch+1}/{epochs}] \"\n",
    "            f\"| Loss: {running_loss/len(train_loader):.4f} \"\n",
    "            f\"| Acc: {100 * correct/total:.2f}%\"\n",
    "        )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0caf425d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nüß† Starting Adversarial Training...\")\n",
    "\n",
    "adv_model = train_adversarial(\n",
    "    model,\n",
    "    train_loader,\n",
    "    criterion,\n",
    "    optimizer,\n",
    "    device=device,\n",
    "    eps=epsilon,\n",
    "    alpha=alpha,\n",
    "    steps=pgd_steps,\n",
    "    epochs=epochs\n",
    ")\n",
    "\n",
    "torch.save(adv_model.state_dict(), adv_checkpoint_path)\n",
    "print(f\"\\n‚úÖ Adversarially trained model saved at: {adv_checkpoint_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "588f1a15",
   "metadata": {},
   "source": [
    "### 6. Evaluate on Clean Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee93c232",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nüìä Evaluating on clean test set...\")\n",
    "metrics_clean = evaluate_model(\n",
    "    model_path=adv_checkpoint_path,\n",
    "    data_dir=data_dir,\n",
    "    batch_size=batch_size,\n",
    "    model_name=model_name,\n",
    "    device=device\n",
    ")\n",
    "\n",
    "print(\"\\nüìà Test Set Performance:\")\n",
    "print(f\"Accuracy:  {metrics['accuracy']*100:.2f}%\")\n",
    "print(f\"Loss:      {metrics['loss']:.4f}\")\n",
    "print(f\"Precision: {metrics['precision']:.4f}\")\n",
    "print(f\"Recall:    {metrics['recall']:.4f}\")\n",
    "print(f\"F1-score:  {metrics['f1']:.4f}\")\n",
    "\n",
    "print(\"\\nüîç Classification metrics per class:\\n\")\n",
    "print(metrics[\"classification_report\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5895724",
   "metadata": {},
   "source": [
    "### 7. Evaluate on Adversarial Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8e8886a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n‚öîÔ∏è Evaluating on PGD adversarial test set...\")\n",
    "adv_dir = '../data/pgd'\n",
    "\n",
    "res_eval = evaluate_adv(\n",
    "    model_path=adv_model,\n",
    "    adv_folder=adv_dir,\n",
    "    device=device,\n",
    "    data_dir=data_dir,\n",
    "    batch_size=batch_size,\n",
    "    mean_std_sample_size=2000,\n",
    "    image_pattern=\"*.tif\"\n",
    ")\n",
    "\n",
    "print(f\"Num images: {res_eval['num_images']}\")\n",
    "\n",
    "print(f\"Accuracy: {res_eval['accuracy']*100:.2f}%\")\n",
    "print(f\"Loss: {res_eval['loss']:.4f}\")\n",
    "print(f\"Precision: {res_eval['precision']:.4f}\")\n",
    "print(f\"Recall: {res_eval['recall']:.4f}\")\n",
    "print(f\"F1-score: {res_eval['f1']:.4f}\")\n",
    "\n",
    "print(\"\\nClassification metrics per category:\\n\\n\", res_eval[\"classification_report\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32d63b45",
   "metadata": {},
   "source": [
    "- Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72baaf03",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(metrics_adv['confusion_matrix'], metrics_adv['class_names'], normalize=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
